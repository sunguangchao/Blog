先来看下入口：
```java
//JavaMain.java
    public static void main(final String[] args) throws IOException {
    //这里我本地启动了zk，所以注释掉了
//        EmbedZookeeperServer.start(EMBED_ZOOKEEPER_PORT);
        CoordinatorRegistryCenter regCenter = setUpRegistryCenter();
        //设置运行情况跟踪配置
        JobEventConfiguration jobEventConfig = new JobEventRdbConfiguration(setUpEventTraceDataSource());
        setUpSimpleJob(regCenter, jobEventConfig);
    }
	//设置注册中心
    private static CoordinatorRegistryCenter setUpRegistryCenter() {
        //基于zookeeper的注册中心配置
        ZookeeperConfiguration zkConfig = new ZookeeperConfiguration(ZOOKEEPER_CONNECTION_STRING, JOB_NAMESPACE);
        //然后基于配置创建用于协调分布式的注册中心
        CoordinatorRegistryCenter result = new ZookeeperRegistryCenter(zkConfig);
        //初始化
        result.init();
        return result;
    }

//ZookeeperRegistryCenter.java
    /**
     *注册中心初始化
    */
    @Override
    public void init() {
        log.debug("Elastic job: zookeeper registry center init, server lists is: {}.", zkConfig.getServerLists());
        //使用到了建造者模式
        CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder()
                .connectString(zkConfig.getServerLists())
                .retryPolicy(new ExponentialBackoffRetry(zkConfig.getBaseSleepTimeMilliseconds(), zkConfig.getMaxRetries(), zkConfig.getMaxSleepTimeMilliseconds()))
                .namespace(zkConfig.getNamespace());
        if (0 != zkConfig.getSessionTimeoutMilliseconds()) {
            builder.sessionTimeoutMs(zkConfig.getSessionTimeoutMilliseconds());
        }
        if (0 != zkConfig.getConnectionTimeoutMilliseconds()) {
            builder.connectionTimeoutMs(zkConfig.getConnectionTimeoutMilliseconds());
        }
        
        if (!Strings.isNullOrEmpty(zkConfig.getDigest())) {
            builder.authorization("digest", zkConfig.getDigest().getBytes(Charsets.UTF_8))
                    .aclProvider(new ACLProvider() {
                    
                        @Override
                        public List<ACL> getDefaultAcl() {
                            return ZooDefs.Ids.CREATOR_ALL_ACL;
                        }
                    
                        @Override
                        public List<ACL> getAclForPath(final String path) {
                            return ZooDefs.Ids.CREATOR_ALL_ACL;
                        }
                    });
        }
        client = builder.build();
        client.start();
        try {
            if (!client.blockUntilConnected(zkConfig.getMaxSleepTimeMilliseconds() * zkConfig.getMaxRetries(), TimeUnit.MILLISECONDS)) {
                client.close();
                throw new KeeperException.OperationTimeoutException();
            }
            //CHECKSTYLE:OFF
        } catch (final Exception ex) {
            //CHECKSTYLE:ON
            RegExceptionHandler.handleException(ex);
        }
    }
```
下面看Main方法里的setUpSimpleJob方法
```java
private static void setUpSimpleJob(final CoordinatorRegistryCenter regCenter, final JobEventConfiguration jobEventConfig) {
    //根据配置，构建作业核心配置，这个配置也就是会写入{name_space}/{job_name}/config
    JobCoreConfiguration coreConfig = JobCoreConfiguration.newBuilder("javaSimpleJob", "0/5 * * * * ?", 3).shardingItemParameters("0=Beijing,1=Shanghai,2=Guangzhou").build();
    //继续生成sample配置
    SimpleJobConfiguration simpleJobConfig = new SimpleJobConfiguration(coreConfig, JavaSimpleJob.class.getCanonicalName());
    //重点来了，新建作业调度器，然后初始化
    new JobScheduler(regCenter, LiteJobConfiguration.newBuilder(simpleJobConfig).build(), jobEventConfig).init();
}

```
作业调度器构造方法
```java
//JobScheduler.java
    private JobScheduler(final CoordinatorRegistryCenter regCenter, final LiteJobConfiguration liteJobConfig, final JobEventBus jobEventBus, final ElasticJobListener... elasticJobListeners) {
        //作业注册表实例 jobInstanceMap存放
        JobRegistry.getInstance().addJobInstance(liteJobConfig.getJobName(), new JobInstance());
        this.liteJobConfig = liteJobConfig;
        this.regCenter = regCenter;
        List<ElasticJobListener> elasticJobListenerList = Arrays.asList(elasticJobListeners);
        //保证传入的listener都能开始
        setGuaranteeServiceForElasticJobListeners(regCenter, elasticJobListenerList);
        //门面设计模式：为一系列复杂的子系统提供一个简单的入口，不需要关心里面实现的细节
        schedulerFacade = new SchedulerFacade(regCenter, liteJobConfig.getJobName(), elasticJobListenerList);
        jobFacade = new LiteJobFacade(regCenter, liteJobConfig.getJobName(), Arrays.asList(elasticJobListeners), jobEventBus);
    }
```

下面看作业调度器的初始化方法

```java
//JobScheduler.java
/**
 * 初始化作业.
 */
public void init() {
    //更新作业配置
    LiteJobConfiguration liteJobConfigFromRegCenter = schedulerFacade.updateJobConfiguration(liteJobConfig);
    //获取作业注册表实例，并设置分片数
    JobRegistry.getInstance().setCurrentShardingTotalCount(liteJobConfigFromRegCenter.getJobName(), liteJobConfigFromRegCenter.getTypeConfig().getCoreConfig().getShardingTotalCount());
    //新建一个作业调度控制器
    JobScheduleController jobScheduleController = new JobScheduleController(
            createScheduler(), createJobDetail(liteJobConfigFromRegCenter.getTypeConfig().getJobClass()), liteJobConfigFromRegCenter.getJobName());
    //添加作业控制调度器
    JobRegistry.getInstance().registerJob(liteJobConfigFromRegCenter.getJobName(), jobScheduleController, regCenter);
    //注册作业启动信息，门面模式
    schedulerFacade.registerStartUpInfo(!liteJobConfigFromRegCenter.isDisabled());
  	jobScheduleController.scheduleJob(liteJobConfigFromRegCenter.getTypeConfig().getCoreConfig().getCron());
}
```



```java
//JobScheduler.java
private JobDetail createJobDetail() {
    //作业执行的入口,定义JobDetail
    JobDetail result = JobBuilder.newJob(LiteJob.class).withIdentity(liteJobConfig.getJobName()).build();
    result.getJobDataMap().put(JOB_FACADE_DATA_MAP_KEY, jobFacade);
    ElasticJob elasticJobInstance = createElasticJobInstance();
    if (elasticJobInstance != null) {
        result.getJobDataMap().put(ELASTIC_JOB_DATA_MAP_KEY, elasticJobInstance);
    }
    return result;
}

//SchedulerFacade.java
    /**
     * 注册作业启动信息.
     * 
     * @param enabled 作业是否启用
     */
    public void registerStartUpInfo(final boolean enabled) {
        //开启所有监听器
        listenerManager.startAllListeners();
        //选举主节点
        leaderService.electLeader();
        //持久化作业服务器线上信息
        serverService.persistOnline(enabled);
        instanceService.persistOnline();
        //设置需要重新分片的标记:{name_space}/{job_name}/leader/sharding/necessary
        shardingService.setReshardingFlag();
        //初始化作业监听服务
        monitorService.listen();
        //调节分布式状态不一致服务
        if (!reconcileService.isRunning()) {
            reconcileService.startAsync();
        }
    }

    /**
     * 注册数据监听器.
     * 
     * @param listener 数据监听器
     */
    public void addDataListener(final TreeCacheListener listener) {
        TreeCache cache = (TreeCache) regCenter.getRawCache("/" + jobName);
        cache.getListenable().addListener(listener);
    }
    
```

这个方法是如何跳转到的？

`JobRunShell#run()`方法里面调用了`job#execute()`

```java
Job job = jec.getJobInstance();
this.jec = new JobExecutionContextImpl(scheduler, firedTriggerBundle, job);
job.execute(jec);
```

每次 Quartz 到达调度时间时，会创建LiteJob对象进行作业执行。

LiteJob实现了quartz的job接口，quartz最终执行是执行这个对象的execute方法

```java
public final class LiteJob implements Job {
    private ElasticJob elasticJob;
    private JobFacade jobFacade;
    public void setElasticJob(ElasticJob elasticJob) {
        this.elasticJob = elasticJob;
    }
    public void setJobFacade(JobFacade jobFacade) {
        this.jobFacade = jobFacade;
    }

    @Override
    public void execute(final JobExecutionContext context) throws JobExecutionException {
        JobExecutorFactory.getJobExecutor(elasticJob, jobFacade).execute();
    }
}
```

通过作业执行器工厂来获取job调度器（通过传入的ElasticJob返回不同的job调度器）

```java
public final class JobExecutorFactory {
    private JobExecutorFactory() {
    }
    /**
     * 获取作业执行器.
     *
     * @param elasticJob 分布式弹性作业
     * @param jobFacade 作业内部服务门面服务
     * @return 作业执行器
     */
    @SuppressWarnings("unchecked")
    public static AbstractElasticJobExecutor getJobExecutor(final ElasticJob elasticJob, final JobFacade jobFacade) {
        if (elasticJob instanceof SimpleJob) {
            return new SimpleJobExecutor((SimpleJob) elasticJob, jobFacade);
        }
        throw new JobConfigurationException("Cannot support job type '%s'", elasticJob.getClass().getCanonicalName());
    }
}
```

这里会返回执行器SimpleJobExecutor

```java
public final class SimpleJobExecutor extends AbstractElasticJobExecutor {
    
    private final SimpleJob simpleJob;
    
    public SimpleJobExecutor(final SimpleJob simpleJob, final JobFacade jobFacade) {
        super(jobFacade);
        this.simpleJob = simpleJob;
    }
    
    @Override
    protected void process(final ShardingContext shardingContext) {
        simpleJob.execute(shardingContext);
    }
}
```

门面模式：要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行。门面模式提供一个高层次的接口，使得子系统易于访问。

然后看执行器的父类的构造方法：

```java
protected AbstractElasticJobExecutor(final JobFacade jobFacade) {
    this.jobFacade = jobFacade;
    //从缓存中读取作业配置
    jobRootConfig = jobFacade.loadJobRootConfiguration(true);
    jobName = jobRootConfig.getTypeConfig().getCoreConfig().getJobName();
    //获取线程池服务(作业每次执行时，可能分配到多个分片项，需要使用线程池实现并行执行。一个作业一个线程池)
    executorService = ExecutorServiceHandlerRegistry.getExecutorServiceHandler(jobName, (ExecutorServiceHandler) getHandler(JobProperties.JobPropertiesEnum.EXECUTOR_SERVICE_HANDLER));
    //获取异常处理器
    jobExceptionHandler = (JobExceptionHandler) getHandler(JobProperties.JobPropertiesEnum.JOB_EXCEPTION_HANDLER);
    //设置分片错误信息集合
    itemErrorMessages = new ConcurrentHashMap<>(jobRootConfig.getTypeConfig().getCoreConfig().getShardingTotalCount(), 1);
}
```

下面看一下作业执行部分,就是`JobExecutorFactory.getJobExecutor(elasticJob, jobFacade).execute();`里的execute方法

![](http://www.iocoder.cn/images/Elastic-Job/2017_09_23/02.png)

```java
/**
 * 执行作业.--见 https://blog.csdn.net/prestigeding/article/details/80106418
 * AbstractElasticJobExecutor.java
 */
public final void execute() {
    try {
        //--检查作业执行环境,本机与注册中心的时间误差秒数不在允许范围所抛出的异常
        jobFacade.checkJobExecutionEnvironment();
    } catch (final JobExecutionEnvironmentException cause) {
        jobExceptionHandler.handleException(jobName, cause);
    }
    // --获取分片上下文环境
    ShardingContexts shardingContexts = jobFacade.getShardingContexts();
	
    String jobUuid = jobFacade.loadJobRootConfiguration(true).getTypeConfig().getCoreConfig().getJobUuid();
    shardingContexts.setJobUuid(jobUuid);

    try {
        //分片任务执行之前调用，模板方法
        jobFacade.beforeJobExecuted(shardingContexts);
        //CHECKSTYLE:OFF
    } catch (final Throwable cause) {
        //CHECKSTYLE:ON
        jobExceptionHandler.handleException(jobName, cause);
    }

    //获取分布式唯一id
    String jobLogUuid = jobFacade.getJobLogUuid();
    shardingContexts.setJobLogUUid(jobLogUuid);
	//发布作业状态追踪事件
    if (shardingContexts.isAllowSendJobEvent()) {
        jobFacade.postJobStatusTraceEvent(JobStatusTraceEvent.traceEventBuild(jobLogUuid,shardingContexts.getJobUuid(),shardingContexts.getTaskId(),State.TASK_STAGING,String.format("Job '%s' execute begin.", jobName)));
    }
    //在一个调度任务触发后如果上一次任务还未执行，则需要设置该分片状态为mirefire,表示错失了一次任务执行。
    //如果还有分片正在执行，说明上次job没有执行完毕，需要设置成misfire,表示错过了一次执行，然后return
    //举例：sharding/1/running
    if (jobFacade.misfireIfRunning(shardingContexts.getShardingItemParameters().keySet())) {
        if (shardingContexts.isAllowSendJobEvent()) {//如果该分片被设置为mirefire并开启了事件跟踪，将事件跟踪保存在数据库中。
            jobFacade.postJobStatusTraceEvent(JobStatusTraceEvent.traceEventBuild(jobLogUuid,shardingContexts.getJobUuid(),shardingContexts.getTaskId(),State.TASK_FINISHED,
                    String.format(
                            "Previous job '%s' - shardingItems '%s' is still running, misfired job will start after previous job completed.", jobName,
                            shardingContexts.getShardingItemParameters().keySet())
            ));
        }
        return;
    }
    //检查是否依赖的job是否已经执行了。
    Date startTime = new Date();
    long dependWaitTime = jobFacade.loadJobRootConfiguration(true).getTypeConfig().getCoreConfig().getDependentWaitTime();
    //会看一个依赖的job列表，
    boolean dependJobFinished = jobFacade.isFinishedForDependJob();
    while (!dependJobFinished) {
        try {
            if ((new Date().getTime() - startTime.getTime()) / 1000 >= dependWaitTime) {
                //依赖检查大于等待时间报警 note by liubin@jiedaibao.com
                jobFacade.postJobAlarmEvent(JobAlarmEvent.init(shardingContexts.getJobLogUUid(),shardingContexts.getJobUuid(),shardingContexts.getTaskId(),shardingContexts.getJobName(),JobAlarmEvent.AlarmSource.WAIT_DEPENDENT,""));
                return;
            }
            Thread.sleep(5000);
            dependJobFinished = jobFacade.isFinishedForDependJob();
        } catch (InterruptedException e) {
            log.error("InterruptedException", e);
        }
    }

    /**
     * --根据失效分片序号构建分片上下文环境，执行该分片上的任务，根据分片上下文环境，执行任务。
     * 执行完本次任务调度后，将删除分片的故障标记，待下一次任务调度时重新分片。删除分片的故障标记代码如下：LiteJobFacade#registerJobCompleted
     */
    if(shardingContexts.isFailoverContexts()) {
        execute(shardingContexts, JobExecutionEvent.ExecutionSource.FAILOVER);
    }else {
        execute(shardingContexts, JobExecutionEvent.ExecutionSource.NORMAL_TRIGGER);
    }
    //执行被跳过触发的作业
    while (jobFacade.isExecuteMisfired(shardingContexts.getShardingItemParameters().keySet())) {
        jobFacade.clearMisfire(shardingContexts.getShardingItemParameters().keySet());
        execute(shardingContexts, JobExecutionEvent.ExecutionSource.MISFIRE);
    }
    //--再次检测，是否有失效转移分片项要执行
    jobFacade.failoverIfNecessary();
    try {
        jobFacade.afterJobExecuted(shardingContexts);
        //CHECKSTYLE:OFF
    } catch (final Throwable cause) {
        //CHECKSTYLE:ON
        jobExceptionHandler.handleException(jobName, cause);
    }
}
```

job执行之前需要执行的方法

```java
    /**
     * --
     * 分片任务执行之前调用，该方法是一个模板方法，
     * 最后一个分片成功启动后调用doBeforeJobExecutedAtLastStarted方法，
     * 该方法为抽象方法，由具体子类实现，如果有其他分片未执行完成，该方法会阻塞等待，或最后启动的分片执行完doBeforeJobExecutedAtLastStarted方法。
     *
     * @param shardingContexts 分片上下文
     */
    @Override
    public final void beforeJobExecuted(final ShardingContexts shardingContexts) {

        if(shardingContexts.getShardingItemParameters().keySet().size()==0){
            //首次启动,如果server下ip节点是disabled的状态,需要return,否则会,死循环到startedFlag代码处
            return;
        }
        if(shardingContexts.isFailoverContexts()){
            //guaranteeService.latchIsAllStarted(shardingContexts);
            String uuid = UUID.randomUUID().toString();
            shardingContexts.setJobLogUUid(uuid);
            jobFacade.postJobExecuteEvent(JobExecuteEvent.executeInit(uuid, shardingContexts.getJobUuid(),shardingContexts.getJobName(), shardingContexts.getTaskId()));
            return;
        }

        /**
         * 这里加这个判断的目的是：
         * 如果是failover的job，例如分片0是failover，那么1号分片如果已经执行完了的话，
         * started/1节点就会被删除。当前failover 0号分片的job就会在这里一直死锁下去！
         */
//        if(shardingContexts.isFailoverContexts()){
//            log.info("beforeJobExecuted isFailoverContexts");
//            return;
//        }
        guaranteeService.latchIsAllStarted(shardingContexts);
        //--使用GuaranteeService注册分片开始，注册节点:$jobname/guarantee/started/${item}
        guaranteeService.registerStart(shardingContexts.getShardingItemParameters().keySet());
        //--判断该任务所有的分片是否都已经注册启动，如果都注册启动，则调用doBeforeJobExecutedAtLastStarted()方法。
        if (guaranteeService.isAllStarted()) {
            doBeforeJobExecutedAtLastStarted(shardingContexts);
            // 此处不能删除start节点，原因是一旦领一个分片挂了，会重新启动，走到这里。如果当前分片给删除了，那么isAllStarted=false,从新启动的那个job会在下面死锁。
            guaranteeService.clearAllStartedInfo();
            return;
        }
        //如果所有分片没有都启动，获取服务器当前时间。
        long before = timeService.getCurrentMillis();
        try {
            log.info("startedWait ing....");
            synchronized (startedWait) {//锁住该job，直到所有分片都启动，解锁
                startedWait.wait(startedTimeoutMilliseconds);
            }
        } catch (final InterruptedException ex) {
            log.info("startedWait InterruptedException");
        }
        //判断唤醒是超时唤醒还是正常唤醒，如果是超时唤醒，清除所有的分片注册启动信息，处理超时异常。
        if (timeService.getCurrentMillis() - before >= startedTimeoutMilliseconds) {
            guaranteeService.clearAllStartedInfo();
            handleTimeout(startedTimeoutMilliseconds);
        }
    }
```



```java
/**
 * zk分布式锁,保障并发检测的正确性
 * @return
 */
public boolean latchIsAllStarted(final ShardingContexts shardingContexts){
	//分布式锁，保证只有一个节点可以执行
    InterProcessMutex lock = new InterProcessMutex(jobNodeStorage.getClient(),jobNodePath.getFullPath(GuaranteeNode.UUID_LATCH));
    try{
        lock.acquire();
        if(hasStartedInstance()){
            shardingContexts.setJobLogUUid(getUuid());
            return false;
        }
        //临时节点：guarantee/uuid/started
        jobNodeStorage.fillEphemeralJobNode(GuaranteeNode.UUID_STARTED,"");
        //临时节点：guarantee/uuid/starttime
      jobNodeStorage.fillEphemeralJobNode(GuaranteeNode.UUID_STARTTIME,System.currentTimeMillis()/1000);
        jobNodeStorage.fillEphemeralJobNode(GuaranteeNode.UUID_TIMEOUT,"NO");
        String uuid = UUID.randomUUID().toString();
        //永久节点：guarantee/uuid/instance
        jobNodeStorage.fillJobNode(GuaranteeNode.UUID_INSTANCE,uuid);
        shardingContexts.setJobLogUUid(uuid);
        jobFacade.postJobExecuteEvent(JobExecuteEvent.executeInit(uuid, shardingContexts.getJobUuid(),shardingContexts.getJobName(), shardingContexts.getTaskId()));
        return true;
    }catch (Exception ex){
        log.error("Elastic job: lock.acquire() latchIsAllStarted failure, error is: ", ex);
        return false;
    }finally {
        try {
            //释放锁
            lock.release();
        } catch (Exception ex) {
            log.error("Elastic job: lock.release() latchIsAllStarted failure, error is: ", ex);
        }
    }
}
```

下面看一下比较核心的execute方法

```java
    /**
     * 两个参数，分别是：分片
     * 执行来源.
     */
  private void execute(final ShardingContexts shardingContexts, final JobExecutionEvent.ExecutionSource executionSource) {
        log.info("AbstractElasticJobExecutor.execute,jobName:{},executionSouce:{}", shardingContexts.getJobName(), executionSource.value);
        //如果作业实例的分片项为空，直接返回
        if (shardingContexts.getShardingItemParameters().isEmpty()) {
            if (shardingContexts.isAllowSendJobEvent()) {
                jobFacade.postJobStatusTraceEvent(JobStatusTraceEvent.traceEventBuild(shardingContexts.getJobLogUUid(), shardingContexts.getJobUuid(), shardingContexts.getTaskId(), State.TASK_FINISHED, String.format("Sharding item for job '%s' is empty.", jobName)));

            }
            return;
        }
        log.info("jobFacade.registerJobBegin,jobName:{}", shardingContexts.getJobName());
        jobFacade.registerJobBegin(shardingContexts);//将running节点建立，如：elastic-job-example-lite-java/javaSimpleJob/sharding/0/running,临时节点

        if (shardingContexts.isAllowSendJobEvent()) {
            jobFacade.postJobStatusTraceEvent(JobStatusTraceEvent.traceEventBuild(shardingContexts.getJobLogUUid(), shardingContexts.getJobUuid(), shardingContexts.getTaskId(), State.TASK_RUNNING, ""));
        }
        try {
            process(shardingContexts, executionSource);
        } finally {
            log.info("jobFacade.registerJobCompleted,jobName:{}", shardingContexts.getJobName());
            //删除了javaSimpleJob/sharding/0/running节点,如果执行的是失效转移分片，则还需删除jobname/sharding/{item_num}/failover分片项
            jobFacade.registerJobCompleted(shardingContexts);
            if (itemErrorMessages.isEmpty()) {
                if (shardingContexts.isAllowSendJobEvent()) {
                    jobFacade.postJobStatusTraceEvent(JobStatusTraceEvent.traceEventBuild(shardingContexts.getJobLogUUid(), shardingContexts.getJobUuid(), shardingContexts.getTaskId(), State.TASK_FINISHED, ""));
                }
            } else {
                if (shardingContexts.isAllowSendJobEvent()) {
                    jobFacade.postJobStatusTraceEvent(JobStatusTraceEvent.traceEventBuild(shardingContexts.getJobLogUUid(), shardingContexts.getJobUuid(), shardingContexts.getTaskId(), State.TASK_ERROR, itemErrorMessages.toString()));
                }
            }
        }
    }
```
taskId:javaSimpleJob@-@0,1,2@-@READY@-@192.168.1.103@-@816

里面调用了process方法

```java
    private void process(final ShardingContexts shardingContexts, final JobExecutionEvent.ExecutionSource executionSource) {
        Collection<Integer> items = shardingContexts.getShardingItemParameters().keySet();
        log.info("job:{}, items count:{}", shardingContexts.getJobName(), items.size());
        if (1 == items.size()) {//如果只有一个分片
            int item = shardingContexts.getShardingItemParameters().keySet().iterator().next();
            //初始化作业执行事件
            JobExecutionEvent jobExecutionEvent = JobExecutionEvent.executeInit(shardingContexts.getJobLogUUid(), shardingContexts.getJobUuid(), shardingContexts.getTaskId(), jobName, executionSource, item);
            log.info("job:{}, begin process!", shardingContexts.getJobName());
            process(shardingContexts, item, jobExecutionEvent);
            log.info("job:{}, end process!", shardingContexts.getJobName());
            return;
        }
        //多个分片使用CountDownLatch来保证所有分片都跑完，程序才继续往下执行
        //复习
        final CountDownLatch latch = new CountDownLatch(items.size());
        for (final int each : items) {
            final JobExecutionEvent jobExecutionEvent = JobExecutionEvent.executeInit(shardingContexts.getJobLogUUid(), shardingContexts.getJobUuid(), shardingContexts.getTaskId(), jobName, executionSource, each);
            if (executorService.isShutdown()) {
                return;
            }
            executorService.submit(new Runnable() {

                @Override
                public void run() {
                    try {
                        log.info("job:{}, begin process!", shardingContexts.getJobName());
                        process(shardingContexts, each, jobExecutionEvent);
                        log.info("job:{}, end process!", shardingContexts.getJobName());
                    } finally {
                        latch.countDown();
                    }
                }
            });
        }
        try {
            log.info("begin latch wait!");
            latch.await();
            log.info("end latch wait!");
        } catch (final InterruptedException ex) {
            log.warn("InterruptedException!", ex);
            Thread.currentThread().interrupt();
        }
    }
```

在作业的执行过程中，如果只有一个分片，作业执行事件初始化后，直接执行；如果是多于一个分片，则使用CountDownLatch，直到所有的分片都完成之后，才算执行完成。



主要是调用了`process(final ShardingContexts shardingContexts, final int item, final JobExecutionEvent startEvent)`方法

```java
    private void process(final ShardingContexts shardingContexts, final int item, final JobExecutionEvent startEvent) {
        if (shardingContexts.isAllowSendJobEvent()) {
            jobFacade.postJobExecutionEvent(startEvent);
        }
        log.trace("Job '{}' executing, item is: '{}'.", jobName, item);
        JobExecutionEvent completeEvent;
        try {
            process(new ShardingContext(shardingContexts, item));
            completeEvent = JobExecutionEvent.executeSuccess(startEvent.getJobLogUuid(), startEvent.getJobUuid(), startEvent.getUuid());
            log.trace("Job '{}' executed, item is: '{}'.", jobName, item);
            if (shardingContexts.isAllowSendJobEvent()) {
                jobFacade.postJobExecutionEvent(completeEvent);
            }
            // CHECKSTYLE:OFF
        } catch (final Throwable cause) {
            // CHECKSTYLE:ON
            completeEvent = JobExecutionEvent.executeFail(startEvent.getJobLogUuid(), startEvent.getJobUuid(), startEvent.getUuid(), cause);
            jobFacade.postJobExecutionEvent(completeEvent);
            itemErrorMessages.put(item, ExceptionUtil.transform(cause));
            jobExceptionHandler.handleException(jobName, cause);
        }
    }
```

里面还有一个抽象的process方法
```java
    protected abstract void process(ShardingContext shardingContext);
```
这里是用了一个模板模式，下面就见到熟悉的部分了。
```java
/**
 * 简单作业执行器.
 * 
 * @author zhangliang
 */
public final class SimpleJobExecutor extends AbstractElasticJobExecutor {
    
    private final SimpleJob simpleJob;
    
    public SimpleJobExecutor(final SimpleJob simpleJob, final JobFacade jobFacade) {
        super(jobFacade);
        this.simpleJob = simpleJob;
    }
    
    @Override
    protected void process(final ShardingContext shardingContext) {
        simpleJob.execute(shardingContext);
    }
}
```
简单作业执行器调用了SimpleJob#execute(ShardingContext shardingContext)方法

```java
public abstract class BaseSimpleJob implements SimpleJob {

    private static final CommonLogger logger = CommonLoggerFactory.getLogger(BaseSimpleJob.class);

    public abstract void doTask(ShardingContext shardingContext);

    @Override
    public void execute(ShardingContext shardingContext) {
        String trace_id = shardingContext.getJobLogUuid();
        long startTime = System.currentTimeMillis();
        String jobName = shardingContext.getJobName();
        MDC.remove(Constants.MDC_TRACE_ID);
        MDC.put(Constants.MDC_TRACE_ID, trace_id);
        logger.info("Starting Job: {}, sharing number:{}", jobName, shardingContext.getShardingItem());
        try {
            doTask(shardingContext);
            logger.info("Finish Job: {}, cost time:{} ms", jobName, (System.currentTimeMillis() - startTime));
        } catch (Throwable ex) {
            logger.error("JobError: {}", jobName, ex);
        } finally {
            logger.info("Exiting Job: {}", jobName);
        }
    }
}
```
BaseSimpleJob抽象类，实现了SimpleJob接口，进行全链路日志traceId的添加
然后这个doTask方法，就是我们常用的业务相关实现job的入口。
job跑完之后，我们需要看下之后elastic job会做出什么处理

```java
    @Override
    public final void afterJobExecuted(final ShardingContexts shardingContexts) {
        guaranteeService.registerComplete(shardingContexts.getShardingItemParameters().keySet());
        if (guaranteeService.isAllCompleted()) {
            doAfterJobExecutedAtLastCompleted(shardingContexts);
            guaranteeService.clearAllCompletedInfo();
            return;
        }
        long before = timeService.getCurrentMillis();
        try {
            synchronized (completedWait) {
                completedWait.wait(completedTimeoutMilliseconds);
            }
        } catch (final InterruptedException ex) {
            Thread.interrupted();
        }
        if (timeService.getCurrentMillis() - before >= completedTimeoutMilliseconds) {
            guaranteeService.clearAllCompletedInfo();
            handleTimeout(completedTimeoutMilliseconds);
        }
    }
```





```java
    /**
     * 分片任务执行之后调用，该方法是一个模板方法，实现当最后一个分片成功执行完成后调用doAfterJobExecutedAtLastCompleted方法，该方法为抽象方法，
     * 由具体子类实现，如果有其他分片未执行完成，该方法会阻塞等待，或最后启动的分片执行完doAfterJobExecutedAtLastCompleted方法。
     *
     * @param shardingContexts 分片上下文
     */
    @Override
    public final void afterJobExecuted(final ShardingContexts shardingContexts) {

        if(shardingContexts.getShardingItemParameters().keySet().size()==0){
            return;
        }
        if(shardingContexts.isFailoverContexts()){
            //看一下
            doAfterJobExecutedAtLastCompleted(shardingContexts);
            return;
        }
        //log.info("afterJobExecuted begin,jobName:{}", shardingContexts.getJobName());
        //临时节点:guarantee/uuid/completed
        guaranteeService.latchIsAllCompleted();
        //guarantee/started/0
        guaranteeService.registerComplete(shardingContexts.getShardingItemParameters().keySet());
        //所有节点都执行完毕
        if (guaranteeService.isAllCompleted()) {
            doAfterJobExecutedAtLastCompleted(shardingContexts);
//            guaranteeService.clearAllStartedInfo();
//            this.startedFlag = false;
            guaranteeService.clearAllCompletedInfo();
            //this.completedFlag = false;
            return;
        }
        long before = timeService.getCurrentMillis();
            try {
                log.info("completedWait ing....");
                synchronized (completedWait) {
                    completedWait.wait(completedTimeoutMilliseconds);
                }
            } catch (final InterruptedException ex) {
                log.info("completedWait InterruptedException");
            }
        if (timeService.getCurrentMillis() - before >= completedTimeoutMilliseconds) {
//            guaranteeService.clearAllStartedInfo();
//            this.startedFlag = false;
            guaranteeService.clearAllCompletedInfo();
            //this.completedFlag = false;
            handleTimeout(completedTimeoutMilliseconds);
        }
    }
```



```java
//LiteJobFacade.java
	@Override
    public ShardingContexts getShardingContexts() {
        boolean isFailover = configService.load(true).isFailover();
        if (isFailover) {//--获取分片上下文时，如果启用了故障失效转移机制，优先获取故障失效转移的分片上下文
            /*
            --获取本节点获取的失效分片信息。其基本逻辑是遍历${namespace}/${jobname}/sharding下的子节点，
            获取该任务当前的所有分片信息，遍历每个节点，获取序号，然后依次判断是否存在(${namespace}/jobname/sharding/{item}/failover),
            并且该节点的内容为当前的实例ID,则加入到分片结果中。
            * */
            //三处调用的地方
            List<Integer> failoverShardingItems = failoverService.getLocalFailoverItems();
            if (!failoverShardingItems.isEmpty()) {
                /**
                 *-- 根据失效分片序号构建分片上下文环境，执行该分片上的任务，根据分片上下文环境，执行任务。
                 * 【AbstractElasticJob#execute(shardingContexts, JobExecutionEvent.ExecutionSource.NORMAL_TRIGGER);】
                 * 执行完本次任务调度后，将删除分片的故障标记，待下一次任务调度时重新分片。
                 */
                ShardingContexts shardingContexts =  executionContextService.getJobShardingContext(failoverShardingItems);
                shardingContexts.setFailoverContexts(true);
                return shardingContexts;
            }
        }
        shardingService.shardingIfNecessary();//--如果有必要，则执行分片，如果不存在分片信息（第一次分片）或需要重新分片，则执行分片算法。
        //--获取本地的分片信息。遍历所有分片信息${namespace}/jobname/sharding/{分片item}下所有instance节点，判断其值jobinstanceId是否与当前的jobInstanceId相等，相等则认为是本节点的分片信息。
        List<Integer> shardingItems = shardingService.getLocalShardingItems();
        if (isFailover) {
            shardingItems.removeAll(failoverService.getLocalTakeOffItems());
        }
        shardingItems.removeAll(executionService.getDisabledItems(shardingItems));//--移除本地禁用分片，本地禁用分片的存储目录为${namespace}/jobname/sharding/{分片item}/disable。
        return executionContextService.getJobShardingContext(shardingItems);//--返回当前节点的分片上下文环境,这个主要是根据配置信息（分片参数）与当前的分片实例，构建ShardingContexts对象。
    }
```



看一下beforeJobExecuted这个方法，是一个模板方法，对每个分片来进行执行

```java
 /**
     * --
     * 分片任务执行之前调用，该方法是一个模板方法，
     * 最后一个分片成功启动后调用doBeforeJobExecutedAtLastStarted方法，
     * 该方法为抽象方法，由具体子类实现，如果有其他分片未执行完成，该方法会阻塞等待，或最后启动的分片执行完doBeforeJobExecutedAtLastStarted方法。
     *
     * @param shardingContexts 分片上下文
     */
    @Override
    public final void beforeJobExecuted(final ShardingContexts shardingContexts) {

        if(shardingContexts.getShardingItemParameters().keySet().size()==0){
            //首次启动,如果server下ip节点是disabled的状态,需要return,否则会,死循环到startedFlag代码处
            return;
        }
        if(shardingContexts.isFailoverContexts()){
            String uuid = UUID.randomUUID().toString();
            shardingContexts.setJobLogUUid(uuid);
            jobFacade.postJobExecuteEvent(JobExecuteEvent.executeInit(uuid, shardingContexts.getJobUuid(),shardingContexts.getJobName(), shardingContexts.getTaskId()));
            return;
        }

        /**
         * 这里加这个判断的目的是：
         * 如果是failover的job，例如分片0是failover，那么1号分片如果已经执行完了的话，
         * started/1节点就会被删除。当前failover 0号分片的job就会在这里一直死锁下去！
         */
//        if(shardingContexts.isFailoverContexts()){
//            log.info("beforeJobExecuted isFailoverContexts");
//            return;
//        }
        guaranteeService.latchIsAllStarted(shardingContexts);
        //--使用GuaranteeService注册分片开始，注册节点:$jobname/guarantee/started/$item
        guaranteeService.registerStart(shardingContexts.getShardingItemParameters().keySet());
        //--判断该任务所有的分片是否都已经注册启动，如果都注册启动，则调用doBeforeJobExecutedAtLastStarted()方法。
        if (guaranteeService.isAllStarted()) {
            doBeforeJobExecutedAtLastStarted(shardingContexts);
            guaranteeService.clearAllStartedInfo();// 此处不能删除start节点，原因是一旦领一个分片挂了，会重新启动，走到这里。如果当前分片给删除了，那么isAllStarted=false,从新启动的那个job会在下面死锁。
            return;
        }
        //--获取服务器当前时间。
        long before = timeService.getCurrentMillis();
        //while (!startedFlag) {
            try {
                log.info("startedWait ing....");
                synchronized (startedWait) {//锁住该job，直到所有分片都启动，解锁
                    startedWait.wait(startedTimeoutMilliseconds);
                }
            } catch (final InterruptedException ex) {
                log.info("startedWait InterruptedException");
//                Thread.interrupted();
            }
//            if(!guaranteeService.isFailoverEnabled()){
//                break;
//            }
//        }

        //判断唤醒是超时唤醒还是正常唤醒，如果是超时唤醒，清除所有的分片注册启动信息，处理超时异常。
        if (timeService.getCurrentMillis() - before >= startedTimeoutMilliseconds) {
            guaranteeService.clearAllStartedInfo();
            handleTimeout(startedTimeoutMilliseconds);
        }
    }
```






选主

```java
/**
 * 在主节点执行操作.
 *
 * @param latchNode 分布式锁使用的作业节点名称
 * @param callback  执行操作的回调
 */
public void executeInLeader(final String latchNode, final LeaderExecutionCallback callback) {
    //latchNode的值：leader/election/latch
    try (LeaderLatch latch = new LeaderLatch(getClient(), jobNodePath.getFullPath(latchNode))) {
        latch.start();//启动LeaderLatch，其主要过程就是去锁路径下创建一个临时排序节点，如果创建的节点序号最小，await方法将返回，
        // 否则在前一个节点监听该节点事件，并阻塞,如何获得分布式锁后，执行callback回调方法
        latch.await();
        /*
        latch.await()函数执行后：A,B进程，会去竞争分布式锁，假如A获得了锁，则B就会wait阻塞，等待A执行完callback.execute();才会解除阻塞，获得锁。
        之所以A的callback.execute()执行完，B就会获得锁是因为这里用到了try(LeaderLatch latch)，它会自动执行latch.close()方法。
        */
        //创建了 jobname/leader/election/instances
        callback.execute();
        //CHECKSTYLE:OFF
    } catch (final Exception ex) {
        //CHECKSTYLE:ON
        handleException(ex);
    }
}
```





```java
/**
 * 如果需要分片且当前节点为主节点, 则作业分片.
 * <p>
 * <p>
 * 如果当前无可用节点则不分片.
 * </p>
 */
public void shardingIfNecessary() {
    //--获取当前可用实例，首先获取\ ${namespace}/jobname/instances目录下的所有子节点，并且判断该实例节点的IP所在服务器是否可用,
    // ${namespace}/jobname/servers/ip节点存储的值如果不是DISABLE，则认为该节点可用。
    List<JobInstance> availableJobInstances = instanceService.getAvailableJobInstances();
    //--如果不需要重新分片（\${namespace}/jobname/leader/sharding/necessary节点不存在）或当前不存在可用实例，则返回
    //(总理问题,如果是第一次启动，necessary不存在吧？，怎么处理？）回：作业服务器上线，会设置需要重新分片的标记，necessary肯定会存在
    if (!isNeedSharding() || availableJobInstances.isEmpty()) {
        return;
    }
    //--判断是否是主节点，如果当前正在进行主节点选举，则阻塞直到选主完成
    if (!leaderService.isLeaderUntilBlock()) {
        //--如果不是leader，则进入到这里，等待leader分片完成。
        blockUntilShardingCompleted();
        return;
    }
    //--能进入到这里，说明该节点是主节点。主节点在执行分片之前，首先等待该批任务全部执行完毕，
    // 判断是否有其他任务在运行的方法是判断是否存在${namespace}/jobname/sharding/{分片item}/running，如果存在，则使用Thread.sleep(100)，然后再判断。
    waitingOtherShardingItemCompleted();
    //--主节点写入正在分片的标记,开始分片
    LiteJobConfiguration liteJobConfig = configService.load(false);
    int shardingTotalCount = liteJobConfig.getTypeConfig().getCoreConfig().getShardingTotalCount();
    log.debug("Job '{}' sharding begin.", jobName);
    //
    //--创建临时节点${namespace}/jobname/leader/sharding/processing节点，表示分片正在执行。
    //--主节点在分片时持有的节点，如果有此节点，所有的作业执行都将阻塞，直至分片结束，主节点分片结束或主节点崩溃会删除此临时节点
    jobNodeStorage.fillEphemeralJobNode(ShardingNode.PROCESSING, "");

    /**
     * 重置分片信息。先删除${namespace}/jobname/sharding/{分片item}/instance节点，然后创建${namespace}/jobname/sharding/{分片item}节点（如有必要)。
     * 然后根据当前配置的分片总数量，如果当前${namespace}/jobname/sharding子节点数大于配置的分片节点数，则删除多余的节点（从大到小删除）。
     */
    resetShardingInfo(shardingTotalCount);

    /**
     * --获取配置的分片算法类，常用的分片算法为平均分片算法
     */
    JobShardingStrategy jobShardingStrategy = JobShardingStrategyFactory.getStrategy(liteJobConfig.getJobShardingStrategyClass());

    //--在一个事务内创建 相应的分片实例信息${namespace}/jobname/{分片item}/instance,节点存放的内容为JobInstance实例的ID。
    jobNodeStorage.executeInTransaction(new PersistShardingInfoTransactionExecutionCallback(jobShardingStrategy.sharding(availableJobInstances, jobName, shardingTotalCount)));
    log.debug("Job '{}' sharding complete.", jobName);
}
```

